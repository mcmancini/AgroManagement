{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example downloader of the ERA5 reanalysis data from Copernicus\n",
    "---\n",
    "**Author**: [Mattia C. Mancini](https://github.com/mcmancini) -- (m.c.mancini@exeter.ac.uk)  \n",
    "**Date**: March 20th, 2024  \n",
    "\n",
    "---\n",
    "\n",
    "This notebook goes through the process of identifying and downloading the ERA5 reanalysis weather data that is needed to compute LAI following the algorithm from [Myrgiotis and Vasilis (2021)](https://datashare.ed.ac.uk/handle/10283/4086). Time-series of vapour pressure deficit (VPD) are required to implement the algorithm and are derived from the '2m_temperature', '2m_dewpoint_temperature' climate variables. Data is downloaded from Copernicus using the [CDS API](https://confluence.ecmwf.int/display/CKB/How+to+download+ERA5). More info on how to optimise data download can be found [here](http://tinyurl.com/5dvy4evm).\n",
    "\n",
    "## Step 1: User registration with Copernicus and set up of API credentials\n",
    "**N.B.**: if you have already run the Sentinel CDSE downloader, then you will have already set the user credentials up and you can skip this step and go to [Step 2](#step-2-download-the-data).  \n",
    "\n",
    "To access Copernicus Sentinel data users will need to [self-register](https://documentation.dataspace.copernicus.eu/Registration.html) on the [Copernicus Data Space Ecosystem](https://dataspace.copernicus.eu/). More information can be found [here](https://scihub.copernicus.eu/).  \n",
    "Data is downloaded from Copernicus using the [CDS API](https://confluence.ecmwf.int/display/CKB/How+to+download+ERA5); for the CDS api to work, the user must specify authentication credentials. These are the ones created when registering with the Copernicus Data Space Ecosystem. To store and access the credentials, create with a text editor a *.netrc* file with the following content:\n",
    "```\n",
    "machine https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\n",
    "login <your username>\n",
    "password <your password>\n",
    "```\n",
    "Save this file in the user home directory. For Windows machines, this is usually `C:\\Users\\<username>\\` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sys path so notebook can access the agromanagement package\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: download the data\n",
    "This requires to define a timeframe of interest, which is as follows:\n",
    "- start date: the initial date in the timeframe of interest, declared in the following format: `\"YYYY-MM-DD\"`\n",
    "- end date: the final date in the timeframe of interest, declared in the following format: `\"YYYY-MM-DD\"`\n",
    "- An optional argument to specify the path where the data needs to be donwloaded. If not declared, the data will be saved in the `resources\\era_5` folder in the main project directory.  \n",
    "\n",
    "**NOTE**: the function to download the data retrieves the data for all the years of interest: this means that specifying only a few months within a year as the timeframe of interest will still download data for the whole year; the reason for this is the fact that the algorithm to compute the LAI requires data organised in complete yearly files (there might be a way to change this in the code, but for now I have not attempted this). Due to the size of the data, downloading the yearly data can't be done in one go, so the process consists on calling the API for monthly chunks of data for all the years, and then aggregate them into single years. The temporary monthly files are deleted once the yearly file has been generated. Due to API rules and downloading quotes, this process is quite slow (possibly also with the fact that the whole Copernicus data ecosystem is being updated). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agromanagement.utility.data_downloaders import download_era\n",
    "\n",
    "# Define timeframe\n",
    "start_date = \"2021-01-01\"\n",
    "end_date = \"2021-02-28\"\n",
    "\n",
    "# Download the data\n",
    "## AAA THIS TAKES A LONG TIME: about 5-6 minutes for each file to download\n",
    "download_era(start_date=start_date, end_date=end_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agromanagement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
