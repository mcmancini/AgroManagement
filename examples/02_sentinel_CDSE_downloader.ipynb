{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example downloader of the Sentinel 1 and Sentinel 2 data from Copernicus\n",
    "---\n",
    "**Author**: [Mattia C. Mancini](https://github.com/mcmancini) -- (m.c.mancini@exeter.ac.uk)  \n",
    "**Date**: March 20th, 2024  \n",
    "\n",
    "---\n",
    "\n",
    "This notebook goes through the process to identifying and downloading the Sentinel 1 data from the [Copernicus Data Space Ecosystem](https://dataspace.copernicus.eu/).\n",
    "\n",
    "## Step 1: User registration with Copernicus and set up of API credentials\n",
    "To access Copernicus Sentinel data users will need to [self-register](https://documentation.dataspace.copernicus.eu/Registration.html) on the [Copernicus Data Space Ecosystem](https://dataspace.copernicus.eu/). More information can be found [here](https://scihub.copernicus.eu/).  \n",
    "We will download data using [APIs](https://scihub.copernicus.eu/twiki/do/view/SciHubWebPortal/APIHubDescription) and the [CDSETool](https://github.com/SDFIdk/CDSETool) python package. Given to the ongoing (as of March 2024) migration from Copernicus Science Hub to the new Data Space Ecosystem, previous packages such as the [Sentinelsat](https://sentinelsat.readthedocs.io/) no longer work. The CDSETool package is a community-developed package that uses [OpenSearch](https://documentation.dataspace.copernicus.eu/APIs/OpenSearch.html) which I find better documented when it comes to features to query compared to [OData](https://documentation.dataspace.copernicus.eu/APIs/OData.html). In case of interest, an official example from the [EU-CDSE Github repository](https://github.com/eu-cdse) using OData can be found [here](https://github.com/eu-cdse/notebook-samples/blob/c0e0ade601973c5d4e4bf66a13c0b76ebb099805/sentinelhub/migration_from_scihub_guide.ipynb).  \n",
    "  \n",
    "\n",
    "For the APIs to work, the user must specify authentication credentials. These are the ones created when registering with the Copernicus Data Space Ecosystem. To store and access the credentials, create with a text editor a *.netrc* file with the following content:\n",
    "```\n",
    "machine https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\n",
    "login <your username>\n",
    "password <your password>\n",
    "```\n",
    "Save this file in the user home directory. For Windows machines, this is usually `C:\\Users\\<username>\\`\n",
    "\n",
    "## Step 2: Connect to the API and query data\n",
    "The first step is to generate a connection to the API with an instance of the class `Credentials` from the **CDSETool** python package.  \n",
    "As we stored user credentials in the *.netrc* file, we do not need to pass them explicitly when generating an instance of the `Credentials` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sys path so notebook can access the agromanagement package\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdsetool.credentials import Credentials\n",
    "\n",
    "# connect to the API\n",
    "credentials = Credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: select an area of interest to download the Sentinel data\n",
    "As for the downloader of the Sentinel 2 L2A data, we identify tiles with the data to donwload from user-inputted geometries. For us, this will likely be field parcels in the UK, which are shapefiles defined in the [CEH Vector Land Cover maps](https://www.ceh.ac.uk/data/ukceh-land-cover-maps). From the geometry of a selected parcel, we will query the correct Sentinel 1 data to download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a parcel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load a parcel from data\n",
    "parcels = gpd.read_file(\"../resources/\" + \"lcm2021_tile_11_1014_647.geojson\")\n",
    "parcel = parcels.iloc[1025:1026, :]\n",
    "print(parcel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the parcel\n",
    "parcel.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geometry of the parcel is what we will be using to query the Sentinel 1 data. The API requires that the footprint of the location of interest is passed in geo-json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import mapping\n",
    "\n",
    "# extract geometry and convert to geojson\n",
    "geometry = parcel.iloc[0, :][\"geometry\"]\n",
    "geom_json = mapping(geometry)\n",
    "print(geom_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: select a temporal timeframe of interest\n",
    "Here we specify the temporal timeframe for which we want data to be downloaded. The Sentinel-1 satellites have a 12-day repeat cycle. We can define dates as `string` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2019-01-01\"\n",
    "end_date = \"2019-01-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: define the product to download\n",
    "Now that we have an API connection, a location and a temporal timeframe of interest, we need to specify the data that we want to download.  \n",
    "As we are using this data to compute Leaf Area Index following the algorithm from [Myrgiotis and Vasilis (2021)](https://datashare.ed.ac.uk/handle/10283/4086), we are interested here in the Sentinel 2 L2A and Sentinel-1 GRD S1-VV/VH dat, but other data can be specified as well. The way the CDSETool package works is to define a collection of search terms or *properties*. I found in the documentation of OpenSearch the list of the available [OpenSearch API search keywords](https://scihub.copernicus.eu/userguide/FullTextSearch#Search_Keywords); however, these do NOT work! (not sure whether I misunderstood how the API works...). The list of available is available invoking the `cdsetool.query()` function from the CDSETool query module.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The values that can be assigned to each of these properties do not always match the [Sentinel 1 naming conventions](https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-1-sar/naming-conventions) or [Sentinel 2 naming conventions](https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-2-msi/naming-convention): for example, for Sentinel 1, `PRODUCT_TYPE` is defined in the properties for the API call as `\"IW_GRDH_1S\"` rather than `GRD` as one would derive from naming conventions. For Sentinel 2, it is defined as `\"S2MSI2A\"` rather than `\"MSIL2A\"`. There are also some other oddities: if wanting to download data with dual polarisation (*DV* in naming conventions) VV+VH, I could not figure out a way to declare it. While it is defined in the returned feature properties as `polarisation: \"VV&VH\"`, if passed into the search as such will not work and return an empty list of features. None of the following works: `\"VVVH\", \"VV&VH\", \"VV+VH\", \"VV/VH\", \"DV\"`. \n",
    "\n",
    "This sample code should allow to download the data we need for the algorithm from [Myrgiotis and Vasilis (2021)](https://datashare.ed.ac.uk/handle/10283/4086) for Sentinel 1:\n",
    "\n",
    "```\n",
    "COLLECTION = \"Sentinel1\"\n",
    "PRODUCT_TYPE = \"IW_GRDH_1S\"\n",
    "\n",
    "\n",
    "search_terms = {\n",
    "    \"maxRecords\": \"2000\",\n",
    "    \"startDate\": start_date,\n",
    "    \"completionDate\": end_date,\n",
    "    \"geometry\": geometry,\n",
    "    \"productType\": PRODUCT_TYPE,\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "This for Sentinel 2:\n",
    "\n",
    "```\n",
    "COLLECTION = \"Sentinel2\"\n",
    "PRODUCT_TYPE = \"S2MSI2A\"\n",
    "\n",
    "\n",
    "search_terms = {\n",
    "    \"maxRecords\": \"2000\",\n",
    "    \"startDate\": start_date,\n",
    "    \"completionDate\": end_date,\n",
    "    \"geometry\": geometry,\n",
    "    \"productType\": PRODUCT_TYPE,\n",
    "}\n",
    "```\n",
    "\n",
    "**NB**  \n",
    "Make sure to change `maxRecords` in your actual script to remove the limit on the features retrieved!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdsetool.query import describe_collection\n",
    "\n",
    "# List all search terms available for the Sentinel1 collection\n",
    "search_properties = describe_collection(\"Sentinel1\").keys()\n",
    "for key in search_properties:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Sentinel 1 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdsetool.query import query_features\n",
    "\n",
    "COLLECTION = \"Sentinel1\"\n",
    "PRODUCT_TYPE = \"IW_GRDH_1S\"\n",
    "\n",
    "search_terms = {\n",
    "    \"maxRecords\": \"2000\",\n",
    "    \"startDate\": start_date,\n",
    "    \"completionDate\": end_date,\n",
    "    \"geometry\": geometry,\n",
    "    \"productType\": PRODUCT_TYPE,\n",
    "}\n",
    "\n",
    "sentinel_1_feature_list = query_features(\n",
    "    collection=COLLECTION, search_terms=search_terms)\n",
    "print(len(sentinel_1_feature_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Sentinel 2 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdsetool.query import query_features\n",
    "\n",
    "COLLECTION = \"Sentinel2\"\n",
    "PRODUCT_TYPE = \"S2MSI2A\"\n",
    "\n",
    "search_terms = {\n",
    "    \"maxRecords\": \"2000\",\n",
    "    \"startDate\": start_date,\n",
    "    \"completionDate\": end_date,\n",
    "    \"geometry\": geometry,\n",
    "    \"productType\": PRODUCT_TYPE,\n",
    "}\n",
    "\n",
    "sentinel_2_feature_list = query_features(\n",
    "    collection=COLLECTION, search_terms=search_terms)\n",
    "print(len(sentinel_2_feature_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from cdsetool.download import download_feature\n",
    "\n",
    "# N.B.: These are large files, about 1.7Gb. It will take more than 10 minutes to run this section!\n",
    "\n",
    "SENTINEL_1_OUTPUT_FOLDER = os.path.join(\"..\", \"resources\", \"sentinel_1\")\n",
    "SENTINEL_2_OUTPUT_FOLDER = os.path.join(\"..\", \"resources\", \"sentinel_l2a\")\n",
    "\n",
    "# create the folders if they do not exist\n",
    "if not os.path.exists(SENTINEL_1_OUTPUT_FOLDER):\n",
    "    os.makedirs(SENTINEL_1_OUTPUT_FOLDER)\n",
    "\n",
    "if not os.path.exists(SENTINEL_2_OUTPUT_FOLDER):\n",
    "    os.makedirs(SENTINEL_2_OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulk download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N.B.: Each file is about 1.7Gb, so this can take more than 6 hours to run depending on Internect speed.\n",
    "\n",
    "for i in sentinel_1_feature_list:\n",
    "    download_feature(i, SENTINEL_1_OUTPUT_FOLDER)\n",
    "    print(f\"feature {i} downloaded\")\n",
    "\n",
    "for i in sentinel_2_feature_list:\n",
    "    download_feature(i, SENTINEL_2_OUTPUT_FOLDER)\n",
    "    print(f\"feature {i} downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download individual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the first in the list of features for Sentinel 1 data.\n",
    "s1_feature = sentinel_1_feature_list[0]\n",
    "download_feature(s1_feature, SENTINEL_1_OUTPUT_FOLDER)\n",
    "\n",
    "# Download the first in the list of features for Sentinel 2 L2A data.\n",
    "s2_feature = sentinel_2_feature_list[0]\n",
    "download_feature(s2_feature, SENTINEL_2_OUTPUT_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agromanagement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
